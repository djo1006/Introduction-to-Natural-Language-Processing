{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "hw_les_8.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "evAcBW0IPvsq",
        "6MZE-Jc6Y9hO",
        "J2QW-TjqZDfq",
        "GwjO-ZJYsxY1",
        "axK2YkJqZGhB"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhHK203SP2OE"
      },
      "source": [
        "#Задание\n",
        "\n",
        "На вебинаре мы говорили что долгое время CNN и RNN архитектуры были конурируещими выяснить какая архитектура больше подходит для задачи сантимент анализа на данных с вебинара\n",
        "1. построить свёрточные архитектуры\n",
        "2. построить различные архитектуры с RNN\n",
        "3. построить совместные архитектуры CNN -> RNN и (RNN -> CNN)\n",
        "4. сдлать выводы что получилось лучше"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nJLwN1qUimN"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGvpV_iwLinj",
        "outputId": "76cb1f6a-4772-48eb-f6e5-4e58066d6ee1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faK_hPKbLVaj"
      },
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/GB/Introduction to Natural Language Processing/lesson_8/'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKmgcUIgLQek",
        "outputId": "e9a9b1d3-31e1-4742-af21-855bf6be3c7d"
      },
      "source": [
        "!pip install stop_words"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting stop_words\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=c6383b69a410f685b7ae87c157b99e47c707bee4d32d4507786fd0ba67e06d69\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tuWw6jCMNGN",
        "outputId": "2e7e2149-8428-4cb3-9a9d-9fc2e259629f"
      },
      "source": [
        "!pip install pymorphy2\n",
        "from pymorphy2 import MorphAnalyzer"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████                          | 10 kB 19.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 30 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 40 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 51 kB 2.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 55 kB 1.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCdcOxNTsxYu"
      },
      "source": [
        "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
        "\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n",
        "df_train = pd.read_csv(f\"{path}/data/train.csv\")\n",
        "df_test = pd.read_csv(f\"{path}/data/test.csv\")\n",
        "df_val = pd.read_csv(f\"{path}/data/val.csv\")\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XzcYZifJsxYv",
        "outputId": "fee953cf-b2a8-469f-f021-eb89c6c5f8aa"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@alisachachka не уезжаааааааай. :(❤ я тоже не ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>RT @epupybobv: Хочется котлету по-киевски. Зап...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>@KarineKurganova @Yess__Boss босапопа есбоса н...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                               text  class\n",
              "0   0  @alisachachka не уезжаааааааай. :(❤ я тоже не ...      0\n",
              "1   1  RT @GalyginVadim: Ребята и девчата!\\nВсе в кин...      1\n",
              "2   2  RT @ARTEM_KLYUSHIN: Кто ненавидит пробки ретви...      0\n",
              "3   3  RT @epupybobv: Хочется котлету по-киевски. Зап...      1\n",
              "4   4  @KarineKurganova @Yess__Boss босапопа есбоса н...      1"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvGm87EIsxYv"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDK5sjELsxYw"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgmp7ed3sxYw"
      },
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2aEm91GsxYx"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsXabgAvsxYx"
      },
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSg57FIgSM6o"
      },
      "source": [
        "result = {'name': list(), 'score': list()}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evAcBW0IPvsq"
      },
      "source": [
        "#SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pehw-QtVsxYy"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkwVf5oksxYz",
        "outputId": "fa6cae4f-d704-4e2d-d584-162841296899"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 44s 131ms/step - loss: 0.5563 - accuracy: 0.7045 - val_loss: 0.4884 - val_accuracy: 0.7569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrYCzDwSsxYz",
        "outputId": "6f309ca4-3a6c-488d-d096-212340271bc7"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 19ms/step - loss: 0.5191 - accuracy: 0.7369\n",
            "\n",
            "\n",
            "Test score: 0.5191256403923035\n",
            "Test accuracy: 0.7368513941764832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxPI5qvISWEM"
      },
      "source": [
        "result['name'].append('SimpleRNN')\n",
        "result['score'].append(score[0])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MZE-Jc6Y9hO"
      },
      "source": [
        "#LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXhckihrsxY0"
      },
      "source": [
        "Какие проблемы у рекурентных сетей?\n",
        "\n",
        "- затухают градиенты\n",
        "- медленно, нужно всегда дойти до конца\n",
        "\n",
        "Как решить? -> LSTM\n",
        "\n",
        "\n",
        "<img src=\"images/lstm.png\">\n",
        "\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "\n",
        "Давайте, кратко посмотрим как это работает:\n",
        "\n",
        "\n",
        "<img src=\"images/LSTMMaths.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v7z5bhUsxY0",
        "outputId": "4580d424-33e4-4ae9-93e6-642400ffc7eb"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 82s 247ms/step - loss: 0.5554 - accuracy: 0.7069 - val_loss: 0.4935 - val_accuracy: 0.7536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVRNC4V1sxY1",
        "outputId": "c6a76ae3-0bad-4c1e-9272-45a013f566ea"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 2s 37ms/step - loss: 0.5088 - accuracy: 0.7458\n",
            "\n",
            "\n",
            "Test score: 0.5088440775871277\n",
            "Test accuracy: 0.7458449006080627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WUiA7q5UHyf"
      },
      "source": [
        "result['name'].append('LSTM')\n",
        "result['score'].append(score[0])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2QW-TjqZDfq"
      },
      "source": [
        "#GRU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwjO-ZJYsxY1"
      },
      "source": [
        "Какие проблемы:\n",
        "\n",
        "- вычислительно сложно -> медленнее\n",
        "- на очень длинных последовательностях все равно затухает градиент\n",
        "\n",
        "\n",
        "Зачем платить больше - уберем некоторые врата (точнее совместим) -> ускоримся, уменьшим число параметров -> GRU\n",
        "\n",
        "\n",
        "<img src=\"images/gru.png\">\n",
        "\n",
        "\n",
        "GRU Math\n",
        "\n",
        "\n",
        "<img src=\"images/GRUMath.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAxpYAwvsxY1",
        "outputId": "c438fece-3119-4a02-abfb-d947f5cf2bc2"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "319/319 [==============================] - 73s 220ms/step - loss: 0.5541 - accuracy: 0.7062 - val_loss: 0.4944 - val_accuracy: 0.7533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW-9odV6UwzG"
      },
      "source": [
        "# plt.figure(figsize=(20,12))\n",
        "# plt.plot(history.history['accuracy'], '-.', label = f'accuracy', color='m')\n",
        "# plt.plot(history.history['val_accuracy'], '-', label = f'val_accuracy', color='g')\n",
        "        \n",
        "# plt.legend()\n",
        "# plt.grid('On')\n",
        "# plt.title('Accuracy of epochs')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.show()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZcwwlYxsxY1",
        "outputId": "a48d9828-c03c-4e85-f2ba-97ca02153a48"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 32ms/step - loss: 0.5082 - accuracy: 0.7461\n",
            "\n",
            "\n",
            "Test score: 0.508188784122467\n",
            "Test accuracy: 0.7460653185844421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "156NIzxcUzX0"
      },
      "source": [
        "result['name'].append('GRU')\n",
        "result['score'].append(score[0])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UrDR7gEVaBe"
      },
      "source": [
        "df_result = pd.DataFrame(result)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axK2YkJqZGhB"
      },
      "source": [
        "#Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "Fd-7nvaaYlMa",
        "outputId": "077684cc-16fa-4fba-88e4-24923ab431ed"
      },
      "source": [
        "df_result"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SimpleRNN</td>\n",
              "      <td>0.519126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LSTM</td>\n",
              "      <td>0.508844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GRU</td>\n",
              "      <td>0.508189</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        name     score\n",
              "0  SimpleRNN  0.519126\n",
              "1       LSTM  0.508844\n",
              "2        GRU  0.508189"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bHi91hrsxY2"
      },
      "source": [
        "3 подхода:\n",
        "\n",
        "<img src=\"images/RNNCompar.png\">\n",
        "\n",
        "\n",
        "Как регуляризовать?\n",
        "- дропаут\n",
        "- рекурентный дропаут\n",
        "\n",
        "\n",
        "<img src=\"images/Dropouts.png\">"
      ]
    }
  ]
}